)
# Since zipcodes can be repeated in the joined accidents data, we need to first get the rows without duplicated zipcodes so we can use it to total population.
unique_zip_data <- accidents_with_zip_data %>%
select(Zipcode, State, Totalpopulation) %>%
distinct() # Removes duplicate ZIP codes
state_summary <- unique_zip_data %>%
group_by(State) %>%
summarise(
total_population = sum(Totalpopulation, na.rm = TRUE) # Sum population for each zipcodes
) %>%
left_join(
accidents_with_zip_data %>% # Join it again so we can calculate the total number of accidents
group_by(State) %>%
summarise(
total_accidents = n(),
mean_household_income = mean(Medianhouseholdincomedollars, na.rm = TRUE)
),
by = "State"
) %>%
arrange(desc(total_accidents))
top_10_states <- state_summary %>%
slice_max(total_accidents, n = 10)
ggplot(top_10_states, aes(x = reorder(State, total_accidents), y = total_accidents)) +
geom_bar(stat = "identity", aes(fill = total_population)) +
scale_fill_viridis_c() +
theme_minimal() +
coord_flip() +
labs(
title = "Top 10 States with the Most Accidents",
x = "State",
y = "Number of Accidents",
fill = "Total Population ($)"
)
unique_travel_time_data <- accidents_with_zip_data %>%
select(Zipcode, State, Meantraveltimetoworkinminutespopulation16yearsandolder) %>%
distinct() %>%
filter(!is.na(Meantraveltimetoworkinminutespopulation16yearsandolder))
state_travel_time_summary <- unique_travel_time_data %>%
group_by(State) %>%
summarise(
mean_travel_time = mean(Meantraveltimetoworkinminutespopulation16yearsandolder, na.rm = TRUE)
) %>%
arrange(desc(mean_travel_time))
travel_time_analysis <- state_summary %>%
left_join(state_travel_time_summary, by = "State")
# Plot relationship
ggplot(travel_time_analysis, aes(x = mean_travel_time, y = total_accidents)) +
geom_point(alpha = 0.6) +
geom_smooth(method = "lm", color = "blue") +
labs(
title = "Accident Frequency vs. Mean Travel Time to Work",
x = "Mean Travel Time (minutes)",
y = "Total Accidents"
) +
theme_minimal()
unique_travel_time_data <- accidents_with_zip_data %>%
select(Zipcode, State, Meantraveltimetoworkinminutespopulation16yearsandolder) %>%
distinct()
state_travel_time_summary <- unique_travel_time_data %>%
group_by(State) %>%
summarise(
mean_travel_time = mean(Meantraveltimetoworkinminutespopulation16yearsandolder, na.rm = TRUE)
) %>%
arrange(desc(mean_travel_time)) %>%
left_join(
accidents_with_zip_data %>% # Join it again so we can calculate the total number of accidents
group_by(State) %>%
summarise(
total_accidents = n(),
mean_travel_time = mean(Meantraveltimetoworkinminutespopulation16yearsandolder, na.rm = TRUE)
),
by = "State"
) %>%
arrange(desc(total_accidents))
travel_time_analysis <- state_summary %>%
left_join(state_travel_time_summary, by = "State")
# Plot relationship
ggplot(travel_time_analysis, aes(x = mean_travel_time, y = total_accidents)) +
geom_point(alpha = 0.6) +
geom_smooth(method = "lm", color = "blue") +
labs(
title = "Accident Frequency vs. Mean Travel Time to Work",
x = "Mean Travel Time (minutes)",
y = "Total Accidents"
) +
theme_minimal()
unique_travel_time_data <- accidents_with_zip_data %>%
select(Zipcode, State, Meantraveltimetoworkinminutespopulation16yearsandolder) %>%
distinct()
state_travel_time_summary <- unique_travel_time_data %>%
group_by(State) %>%
summarise(
mean_travel_time = mean(Meantraveltimetoworkinminutespopulation16yearsandolder, na.rm = TRUE)
) %>%
arrange(desc(mean_travel_time)) %>%
left_join(
accidents_with_zip_data %>% # Join it again so we can calculate the total number of accidents
group_by(State) %>%
arrange(desc(total_accidents))
travel_time_analysis <- state_summary %>%
unique_travel_time_data <- accidents_with_zip_data %>%
select(Zipcode, State, Meantraveltimetoworkinminutespopulation16yearsandolder) %>%
distinct()
state_travel_time_summary <- unique_travel_time_data %>%
group_by(State) %>%
summarise(
mean_travel_time = mean(Meantraveltimetoworkinminutespopulation16yearsandolder, na.rm = TRUE)
) %>%
arrange(desc(mean_travel_time)) %>%
left_join(
accidents_with_zip_data) %>%
arrange(desc(total_accidents))
unique_travel_time_data <- accidents_with_zip_data %>%
select(Zipcode, State, Meantraveltimetoworkinminutespopulation16yearsandolder) %>%
distinct()
state_travel_time_summary <- unique_travel_time_data %>%
group_by(State) %>%
summarise(
mean_travel_time = mean(Meantraveltimetoworkinminutespopulation16yearsandolder, na.rm = TRUE)
) %>%
arrange(desc(mean_travel_time)) %>%
left_join(
accidents_with_zip_data, by = "State") %>%
arrange(desc(total_accidents))
unique_travel_time_data <- accidents_with_zip_data %>%
select(Zipcode, State, Meantraveltimetoworkinminutespopulation16yearsandolder) %>%
distinct()
state_travel_time_summary <- unique_travel_time_data %>%
group_by(State) %>%
summarise(
mean_travel_time = mean(Meantraveltimetoworkinminutespopulation16yearsandolder, na.rm = TRUE)
) %>%
arrange(desc(mean_travel_time))
state_summary <- state_accident_summary %>%
left_join(state_travel_time_summary, by = "State") %>% # Add travel time data
arrange(desc(total_accidents))
library(readr)
library(dplyr)
#Using data.table library to use 'fread'. I found this resource while researching online and is used to load large datasets. This is much faster than read_csv
library(data.table)
library(tidyverse)
library(dcData)
data("ZipDemography")
cleaned_accident_data <- fread("US_Accidents_March23_100K.csv")
head(cleaned_accident_data, 4)
cleaned_accident_data <- cleaned_accident_data %>%
filter(
!is.na(Severity),
!is.na(Start_Time),
!is.na(Zipcode),
!is.na(Weather_Condition),
!is.na(State)
) %>%
mutate(Start_Time = ymd_hms(Start_Time)) %>%
select(Severity, Start_Time, Zipcode, Weather_Condition, State)
weather_summary <- cleaned_accident_data %>%
group_by(Weather_Condition) %>%
summarise(
count = n(),
avg_severity = mean(Severity), # Averaging the severity score for weather condition
) %>%
arrange(desc(count)) %>%
slice_head(n = 15)  # Taking only top 15 into account because conditions with less data do not tell us much
ggplot(weather_summary,
aes(x = reorder(Weather_Condition, count), y = count)) +
geom_bar(stat = "identity", aes(fill = avg_severity)) +
coord_flip() +
scale_fill_viridis_c() +
theme_minimal() +
labs(
title = "Accident Frequency and Severity by Weather Condition",
x = "Weather Condition",
y = "Number of Accidents",
fill = "Average\nSeverity"
)
cleaned_accident_data <- cleaned_accident_data %>%
mutate(hour = hour(Start_Time))
time_weather_summary <- cleaned_accident_data %>%
group_by(hour) %>%
summarise(
count = n(),
avg_severity = mean(Severity)
)
ggplot(time_weather_summary,
aes(x = hour, y = count)) +
geom_bar(stat = "identity", aes(fill = avg_severity)) +
scale_fill_viridis_c() +
theme_minimal() +
labs(
title = "Accident Frequency and Severity by Hour",
x = "Hour",
y = "Number of Accidents",
fill = "Average\nSeverity"
)
# Getting data from ZipDemography
zip_data <- ZipDemography %>%
filter(!is.na(Totalpopulation)) %>% # Remove rows not containing total population
select(Totalpopulation, ZIP, Meantraveltimetoworkinminutespopulation16yearsandolder) # Only select required fields
# Removing '-' from zipcodes in accidents data. For example 123456-4123 -> 123456
cleaned_accident_data <- cleaned_accident_data %>%
mutate(Zipcode = str_extract(Zipcode, "^[0-9]+")) # This matches a string with digits in the beginning until we see a non digit
# Join Accident Data with ZipDemography
accidents_with_zip_data <- cleaned_accident_data %>%
left_join(zip_data, by = c(Zipcode = "ZIP"))
# Since zipcodes can be repeated in the joined accidents data, we need to first get the rows without duplicated zipcodes so we can use it to total population.
unique_zip_data <- accidents_with_zip_data %>%
select(Zipcode, State, Totalpopulation) %>%
distinct() # Removes duplicate ZIP codes
state_summary <- unique_zip_data %>%
group_by(State) %>%
summarise(
total_population = sum(Totalpopulation, na.rm = TRUE) # Sum population for each zipcodes
) %>%
left_join(
accidents_with_zip_data %>% # Join it again so we can calculate the total number of accidents
group_by(State) %>%
summarise(
total_accidents = n(),
mean_household_income = mean(Medianhouseholdincomedollars, na.rm = TRUE)
),
by = "State"
) %>%
arrange(desc(total_accidents))
# Since zipcodes can be repeated in the joined accidents data, we need to first get the rows without duplicated zipcodes so we can use it to total population.
unique_zip_data <- accidents_with_zip_data %>%
select(Zipcode, State, Totalpopulation) %>%
distinct() # Removes duplicate ZIP codes
state_summary <- unique_zip_data %>%
group_by(State) %>%
summarise(
total_population = sum(Totalpopulation, na.rm = TRUE) # Sum population for each zipcodes
) %>%
left_join(
accidents_with_zip_data %>% # Join it again so we can calculate the total number of accidents
group_by(State) %>%
summarise(
total_accidents = n(),
mean_household_income = mean(Medianhouseholdincomedollars, na.rm = TRUE)
),
by = "State"
) %>%
arrange(desc(total_accidents))
# Since zipcodes can be repeated in the joined accidents data, we need to first get the rows without duplicated zipcodes so we can use it to total population.
unique_zip_data <- accidents_with_zip_data %>%
select(Zipcode, State, Totalpopulation) %>%
distinct() # Removes duplicate ZIP codes
state_summary <- unique_zip_data %>%
group_by(State) %>%
summarise(
total_population = sum(Totalpopulation, na.rm = TRUE) # Sum population for each zipcodes
) %>%
left_join(
accidents_with_zip_data %>% # Join it again so we can calculate the total number of accidents
group_by(State) %>%
summarise(
total_accidents = n()
),
by = "State"
) %>%
arrange(desc(total_accidents))
top_10_states <- state_summary %>%
slice_max(total_accidents, n = 10)
library(readr)
library(dplyr)
#Using data.table library to use 'fread'. I found this resource while researching online and is used to load large datasets. This is much faster than read_csv
library(data.table)
library(tidyverse)
library(dcData)
data("ZipDemography")
cleaned_accident_data <- fread("US_Accidents_March23_100K.csv")
head(cleaned_accident_data, 4)
cleaned_accident_data <- cleaned_accident_data %>%
filter(
!is.na(Severity),
!is.na(Start_Time),
!is.na(Zipcode),
!is.na(Weather_Condition),
!is.na(State)
) %>%
mutate(Start_Time = ymd_hms(Start_Time)) %>%
select(Severity, Start_Time, Zipcode, Weather_Condition, State)
weather_summary <- cleaned_accident_data %>%
group_by(Weather_Condition) %>%
summarise(
count = n(),
avg_severity = mean(Severity), # Averaging the severity score for weather condition
) %>%
arrange(desc(count)) %>%
slice_head(n = 15)  # Taking only top 15 into account because conditions with less data do not tell us much
ggplot(weather_summary,
aes(x = reorder(Weather_Condition, count), y = count)) +
geom_bar(stat = "identity", aes(fill = avg_severity)) +
coord_flip() +
scale_fill_viridis_c() +
theme_minimal() +
labs(
title = "Accident Frequency and Severity by Weather Condition",
x = "Weather Condition",
y = "Number of Accidents",
fill = "Average\nSeverity"
)
cleaned_accident_data <- cleaned_accident_data %>%
mutate(hour = hour(Start_Time))
time_weather_summary <- cleaned_accident_data %>%
group_by(hour) %>%
summarise(
count = n(),
avg_severity = mean(Severity)
)
ggplot(time_weather_summary,
aes(x = hour, y = count)) +
geom_bar(stat = "identity", aes(fill = avg_severity)) +
scale_fill_viridis_c() +
theme_minimal() +
labs(
title = "Accident Frequency and Severity by Hour",
x = "Hour",
y = "Number of Accidents",
fill = "Average\nSeverity"
)
# Getting data from ZipDemography
zip_data <- ZipDemography %>%
filter(!is.na(Totalpopulation)) %>% # Remove rows not containing total population
select(Totalpopulation, ZIP, Meantraveltimetoworkinminutespopulation16yearsandolder) # Only select required fields
# Removing '-' from zipcodes in accidents data. For example 123456-4123 -> 123456
cleaned_accident_data <- cleaned_accident_data %>%
mutate(Zipcode = str_extract(Zipcode, "^[0-9]+")) # This matches a string with digits in the beginning until we see a non digit
# Join Accident Data with ZipDemography
accidents_with_zip_data <- cleaned_accident_data %>%
left_join(zip_data, by = c(Zipcode = "ZIP"))
# Since zipcodes can be repeated in the joined accidents data, we need to first get the rows without duplicated zipcodes so we can use it to total population.
unique_zip_data <- accidents_with_zip_data %>%
select(Zipcode, State, Totalpopulation) %>%
distinct() # Removes duplicate ZIP codes
state_summary <- unique_zip_data %>%
group_by(State) %>%
summarise(
total_population = sum(Totalpopulation, na.rm = TRUE) # Sum population for each zipcodes
) %>%
left_join(
accidents_with_zip_data %>% # Join it again so we can calculate the total number of accidents
group_by(State) %>%
summarise(
total_accidents = n()
),
by = "State"
) %>%
arrange(desc(total_accidents))
top_10_states <- state_summary %>%
slice_max(total_accidents, n = 10)
ggplot(top_10_states, aes(x = reorder(State, total_accidents), y = total_accidents)) +
geom_bar(stat = "identity", aes(fill = total_population)) +
scale_fill_viridis_c() +
theme_minimal() +
coord_flip() +
labs(
title = "Top 10 States with the Most Accidents",
x = "State",
y = "Number of Accidents",
fill = "Total Population"
)
travel_time_data <- accidents_with_zip_data %>%
group_by(Zipcode) %>%
summarise(
mean_travel_time = mean(Meantraveltimetoworkinminutespopulation16yearsandolder, na.rm = TRUE), # Calculating mean travel time
total_accidents = n()
)
ggplot(travel_time_analysis, aes(x = mean_travel_time, y = total_accidents)) +
geom_point(alpha = 0.6) +
geom_smooth(method = "lm", color = "blue") +
labs(
title = "Accident Frequency vs. Mean Travel Time to Work",
x = "Mean Travel Time (minutes)",
y = "Total Accidents"
) +
theme_minimal()
travel_time_data <- accidents_with_zip_data %>%
group_by(Zipcode) %>%
summarise(
mean_travel_time = mean(Meantraveltimetoworkinminutespopulation16yearsandolder, na.rm = TRUE), # Calculating mean travel time
total_accidents = n()
)
ggplot(travel_time_data, aes(x = mean_travel_time, y = total_accidents)) +
geom_point(alpha = 0.6) +
geom_smooth(method = "lm", color = "blue") +
labs(
title = "Accident Frequency vs. Mean Travel Time to Work",
x = "Mean Travel Time (minutes)",
y = "Total Accidents"
) +
theme_minimal()
ggplot(travel_time_data, aes(x = mean_travel_time, y = total_accidents)) +
geom_point(alpha = 0.6) +
labs(
title = "Accident Frequency vs. Mean Travel Time to Work",
x = "Mean Travel Time (minutes)",
y = "Total Accidents"
) +
theme_minimal()
library(readr)
library(dplyr)
#Using data.table library to use 'fread'. I found this resource while researching online and is used to load large datasets. This is much faster than read_csv
library(data.table)
library(tidyverse)
library(dcData)
data("ZipDemography")
cleaned_accident_data <- fread("US_Accidents_March23_100K.csv")
head(cleaned_accident_data, 4)
cleaned_accident_data <- cleaned_accident_data %>%
filter(
!is.na(Severity),
!is.na(Start_Time),
!is.na(Zipcode),
!is.na(Weather_Condition),
!is.na(State)
) %>%
mutate(Start_Time = ymd_hms(Start_Time)) %>%
select(Severity, Start_Time, Zipcode, Weather_Condition, State)
weather_summary <- cleaned_accident_data %>%
group_by(Weather_Condition) %>%
summarise(
count = n(),
avg_severity = mean(Severity), # Averaging the severity score for weather condition
) %>%
arrange(desc(count)) %>%
slice_head(n = 15)  # Taking only top 15 into account because conditions with less data do not tell us much
ggplot(weather_summary,
aes(x = reorder(Weather_Condition, count), y = count)) +
geom_bar(stat = "identity", aes(fill = avg_severity)) +
coord_flip() +
scale_fill_viridis_c() +
theme_minimal() +
labs(
title = "Accident Frequency and Severity by Weather Condition",
x = "Weather Condition",
y = "Number of Accidents",
fill = "Average\nSeverity"
)
cleaned_accident_data <- cleaned_accident_data %>%
mutate(hour = hour(Start_Time))
time_weather_summary <- cleaned_accident_data %>%
group_by(hour) %>%
summarise(
count = n(),
avg_severity = mean(Severity)
)
ggplot(time_weather_summary,
aes(x = hour, y = count)) +
geom_bar(stat = "identity", aes(fill = avg_severity)) +
scale_fill_viridis_c() +
theme_minimal() +
labs(
title = "Accident Frequency and Severity by Hour",
x = "Hour",
y = "Number of Accidents",
fill = "Average\nSeverity"
)
# Getting data from ZipDemography
zip_data <- ZipDemography %>%
filter(!is.na(Totalpopulation)) %>% # Remove rows not containing total population
select(Totalpopulation, ZIP, Meantraveltimetoworkinminutespopulation16yearsandolder) # Only select required fields
# Removing '-' from zipcodes in accidents data. For example 123456-4123 -> 123456
cleaned_accident_data <- cleaned_accident_data %>%
mutate(Zipcode = str_extract(Zipcode, "^[0-9]+")) # This matches a string with digits in the beginning until we see a non digit
# Join Accident Data with ZipDemography
accidents_with_zip_data <- cleaned_accident_data %>%
left_join(zip_data, by = c(Zipcode = "ZIP"))
# Since zipcodes can be repeated in the joined accidents data, we need to first get the rows without duplicated zipcodes so we can use it to total population.
unique_zip_data <- accidents_with_zip_data %>%
select(Zipcode, State, Totalpopulation) %>%
distinct() # Removes duplicate ZIP codes
state_summary <- unique_zip_data %>%
group_by(State) %>%
summarise(
total_population = sum(Totalpopulation, na.rm = TRUE) # Sum population for each zipcodes
) %>%
left_join(
accidents_with_zip_data %>% # Join it again so we can calculate the total number of accidents
group_by(State) %>%
summarise(
total_accidents = n()
),
by = "State"
) %>%
arrange(desc(total_accidents))
top_10_states <- state_summary %>%
slice_max(total_accidents, n = 10)
ggplot(top_10_states, aes(x = reorder(State, total_accidents), y = total_accidents)) +
geom_bar(stat = "identity", aes(fill = total_population)) +
scale_fill_viridis_c() +
theme_minimal() +
coord_flip() +
labs(
title = "Top 10 States with the Most Accidents",
x = "State",
y = "Number of Accidents",
fill = "Total Population"
)
travel_time_data <- accidents_with_zip_data %>%
group_by(Zipcode) %>%
summarise(
mean_travel_time = mean(Meantraveltimetoworkinminutespopulation16yearsandolder, na.rm = TRUE), # Calculating mean travel time
total_accidents = n()
)
ggplot(travel_time_data, aes(x = mean_travel_time, y = total_accidents)) +
geom_point(alpha = 0.6) +
labs(
title = "Accident Frequency vs. Mean Travel Time to Work",
x = "Mean Travel Time (minutes)",
y = "Total Accidents"
) +
theme_minimal()
